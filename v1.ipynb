{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "sp_mod = spacy.load(\"en_core_web_sm\")\n",
    "import os, sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_expand(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, df[lst_cols[0]].str.len())\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['/Users/Mohit/Desktop/Work/Shreays Dataset/chuncker_raw_new_dataset/cnn/del/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('/Users/Mohit/Desktop/Work/Shreays Dataset/chuncker_raw_new_dataset/cnn/del/*.story', recursive = True)\n",
    "# filenames = filenames[0]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {} \n",
    "allstory_list = []\n",
    "for filename in filenames: \n",
    "    with open(filename, \"r\") as file: \n",
    "        if filename in files: \n",
    "            continue \n",
    "        files[filename] = file.read() \n",
    "for filename, text in files.items(): \n",
    "    allstory_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allstory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for i in range(len(allstory_list)):\n",
    "    res_list = allstory_list[0].splitlines()\n",
    "    res = [ele for ele in res_list if ele != []]\n",
    "    res = [x for x in res if x]\n",
    "    res = res[: len(res) - 8]\n",
    "    final_list.append(res)\n",
    "    # print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [['(CNN) -- Can a movie actually convince you to support torture? Can a movie really persuade you that \"fracking\" -- a process used to drill for natural gas -- is a danger to the environment? Can a movie truly cause you to view certain minority groups in a negative light?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['(CNN) -- Can a movie actually convince you to support torture? Can a movie really persuade you that \"fracking\" -- a process used to drill for natural gas -- is a danger to the environment? Can a movie truly cause you to view certain minority groups in a negative light?']]"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'(CNN) -- Can a movie actually convince you to support torture? Can a movie really persuade you that \"fracking\" -- a process used to drill for natural gas -- is a danger to the environment? Can a movie truly cause you to view certain minority groups in a negative light?'"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "final_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.strip()\n",
    "doc = sp_mod(text)\n",
    "sents = [elem for elem in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMP\n",
    "\n",
    "for i in range(len(final_list)):\n",
    "    for j in range(len(final_list[i])):\n",
    "        new_sents = [] # for sentences with lenght greater than 5\n",
    "        text = final_list[i][j]\n",
    "        doc = sp_mod(text)\n",
    "        # Tokenise the sentence\n",
    "        sents = [elem for elem in doc.sents]\n",
    "        # Idnetify the length of the sentence\n",
    "        sents_len = [len(elem) for elem in doc.sents]\n",
    "        \n",
    "        # Ignore the tokenise setence with length less than 5 \n",
    "        for k in range(len(sents_len)):\n",
    "            if sents_len[k] > 5:\n",
    "                new_sents.append(sents[k])\n",
    "        \n",
    "        # Assign to final list\n",
    "        final_list[i][j] = new_sents\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[[Can a movie actually convince you to support torture?,\n",
       "   Can a movie really persuade you that \"fracking\" -- a process used to drill for natural gas -- is a danger to the environment?,\n",
       "   Can a movie truly cause you to view certain minority groups in a negative light?]]]"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(final_list)):\n",
    "#     for j in range(len(final_list[i])):\n",
    "#         new_sents = [] # for sentences with lenght greater than 5\n",
    "#         text = final_list[i][j]\n",
    "#         doc = sp_mod(text)\n",
    "#         # Tokenise the sentence\n",
    "#         sents = [elem for elem in doc.sents]\n",
    "#         # Idnetify the length of the sentence\n",
    "#         sents_len = [len(elem) for elem in doc.sents]\n",
    "        \n",
    "#         # Ignore the tokenise setence with length less than 5 \n",
    "#         for k in range(len(sents_len)):\n",
    "#             if sents_len[k] > 5:\n",
    "#                 new_sents.append(sents[k])\n",
    "        \n",
    "#         print(new_sents)\n",
    "#         print(len(new_sents))\n",
    "df = pd.DataFrame(columns=['sent_list'], index = range(1))\n",
    "df['sent_list'][0] = new_sents\n",
    "\n",
    "df['sent_len'] = None\n",
    "for i in range(df.shape[0]):\n",
    "    df['sent_len'][i] = len(df['sent_list'][i])\n",
    "df = df[df['sent_len']>1]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['sent-1'] = None\n",
    "df['sent-2'] = None\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "\n",
    "    sent_1_list = []\n",
    "    sent_2_list = []\n",
    "    for j in range(df['sent_len'][i]):\n",
    "\n",
    "        sent_1_list.append(df['sent_list'][i][j])\n",
    "        if j+1 < df['sent_len'][i]:\n",
    "            sent_2_list.append(df['sent_list'][i][j+1])\n",
    "    df['sent-1'][i] = sent_1_list\n",
    "    df['sent-2'][i] = sent_2_list\n",
    "    \n",
    "    if len(df['sent-1'][i]) > len(df['sent-2'][i]):\n",
    "        df['sent-1'][i].pop()\n",
    "\n",
    "\n",
    "col_list = ['sent-1','sent-2']\n",
    "df = cell_expand(df, lst_cols=col_list)\n",
    "\n",
    "df['sent-1'] = df['sent-1'].astype('str')\n",
    "df['sent-2'] = df['sent-2'].astype('str')\n",
    "df['sent-1'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['sent-1'], inplace=True)\n",
    "df['sent-2'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['sent-2'], inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(final_list)):\n",
    "#     for j in range(len(final_list[i])):\n",
    "#         new_sents = [] # for sentences with lenght greater than 5\n",
    "#         text = final_list[i][j]\n",
    "#         doc = sp_mod(text)\n",
    "#         # Tokenise the sentence\n",
    "#         sents = [elem for elem in doc.sents]\n",
    "#         # Idnetify the length of the sentence\n",
    "#         sents_len = [len(elem) for elem in doc.sents]\n",
    "        \n",
    "#         # Ignore the tokenise setence with length less than 5 \n",
    "#         for k in range(len(sents_len)):\n",
    "#             if sents_len[k] > 5:\n",
    "#                 new_sents.append(sents[k])\n",
    "        \n",
    "#         print(new_sents)\n",
    "#         print(len(new_sents))\n",
    "#         df = pd.DataFrame(columns=['sent_list'], index = range(1))\n",
    "#         df['sent_list'][0] = new_sents\n",
    "\n",
    "#         df['sent_len'] = None\n",
    "#         for i in range(df.shape[0]):\n",
    "#             df['sent_len'][i] = len(df['sent_list'][i])\n",
    "#         df = df[df['sent_len']>1]\n",
    "#         df = df.reset_index(drop=True)\n",
    "        \n",
    "#         df['sent-1'] = None\n",
    "#         df['sent-2'] = None\n",
    "\n",
    "#         for i in range(df.shape[0]):\n",
    "\n",
    "#             sent_1_list = []\n",
    "#             sent_2_list = []\n",
    "#             for j in range(df['sent_len'][i]):\n",
    "\n",
    "#                 sent_1_list.append(df['sent_list'][i][j])\n",
    "#                 if j+1 < df['sent_len'][i]:\n",
    "#                     sent_2_list.append(df['sent_list'][i][j+1])\n",
    "#             df['sent-1'][i] = sent_1_list\n",
    "#             df['sent-2'][i] = sent_2_list\n",
    "            \n",
    "#             if len(df['sent-1'][i]) > len(df['sent-2'][i]):\n",
    "#                 df['sent-1'][i].pop()\n",
    "\n",
    "        \n",
    "#         col_list = ['sent-1','sent-2']\n",
    "#         df = cell_expand(df, lst_cols=col_list)\n",
    "\n",
    "#         df['sent-1'] = df['sent-1'].astype('str')\n",
    "#         df['sent-2'] = df['sent-2'].astype('str')\n",
    "#         df['sent-1'].replace('', np.nan, inplace=True)\n",
    "#         df.dropna(subset=['sent-1'], inplace=True)\n",
    "#         df['sent-2'].replace('', np.nan, inplace=True)\n",
    "#         df.dropna(subset=['sent-2'], inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                           sent_list sent_len  \\\n",
       "0  [(Can, a, movie, actually, convince, you, to, ...        3   \n",
       "1  [(Can, a, movie, actually, convince, you, to, ...        3   \n",
       "\n",
       "                                              sent-1  \\\n",
       "0  Can a movie actually convince you to support t...   \n",
       "1  Can a movie really persuade you that \"fracking...   \n",
       "\n",
       "                                              sent-2  \n",
       "0  Can a movie really persuade you that \"fracking...  \n",
       "1  Can a movie truly cause you to view certain mi...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_list</th>\n      <th>sent_len</th>\n      <th>sent-1</th>\n      <th>sent-2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[(Can, a, movie, actually, convince, you, to, ...</td>\n      <td>3</td>\n      <td>Can a movie actually convince you to support t...</td>\n      <td>Can a movie really persuade you that \"fracking...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[(Can, a, movie, actually, convince, you, to, ...</td>\n      <td>3</td>\n      <td>Can a movie really persuade you that \"fracking...</td>\n      <td>Can a movie truly cause you to view certain mi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sent-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text\n",
       "0  (Can, a, movie, actually, convince, you, to, s...\n",
       "1  (Can, a, movie, really, persuade, you, that, \"...\n",
       "2  (Can, a, movie, truly, cause, you, to, view, c..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(Can, a, movie, actually, convince, you, to, s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(Can, a, movie, really, persuade, you, that, \"...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(Can, a, movie, truly, cause, you, to, view, c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['text'], index = range(len(final_list[0][0])))\n",
    "df['text'] = final_list[0][0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "type(final_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-130-b68232bf6ffd>, line 9)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-130-b68232bf6ffd>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    #     print(\"\\n\")\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(final_list)):\n",
    "    for j in range(len(final_list[i])):\n",
    "        print(len(final_list[i][j]))\n",
    "        print(final_list[i][j])\n",
    "        if len(final_list[i][j]) > 2:\n",
    "            \n",
    "        # for k in range(len(final_list[i][j])):\n",
    "        #     print(final_list[i][j][k])\n",
    "        #     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}